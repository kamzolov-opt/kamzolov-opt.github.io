@article{kamzolov2021universal,
   abstract = { In this paper, we propose new first-order methods for minimization of a convex function on a simple convex set. We assume that the objective function is a composite function given as a sum of a simple convex function and a convex function with inexact Hölder-continuous subgradient. We propose Universal Intermediate Gradient Method. Our method enjoys both the universality and intermediateness properties. Following the ideas of Nesterov (Math. Program. 152 (2015), pp. 381–404) on Universal Gradient Methods, our method does not require any information about the Hölder parameter and constant and adjusts itself automatically to the local level of smoothness. On the other hand, in the spirit of the Intermediate Gradient Method proposed by Devolder et. al. (CORE Discussion Paper 2013/17, 2013), our method is intermediate in the sense that it interpolates between Universal Gradient Method and Universal Fast Gradient Method. This allows to balance the rate of convergence of the method and rate of the oracle error accumulation. Under the additional assumption of strong convexity of the objective, we show how the restart technique can be used to obtain an algorithm with faster rate of convergence. },
   author = {Dmitry Kamzolov and Pavel Dvurechensky and Alexander Gasnikov},
   doi = {10.1080/10556788.2019.1711079},
   issue = {6},
   journal = {Optimization Methods and Software},
   pages = {1289-1316},
   publisher = {Taylor & Francis},
   title = {Universal intermediate gradient method for convex problems with inexact oracle},
   volume = {36},
   url = {https://doi.org/10.1080/10556788.2019.1711079},
   year = {2021},
}
